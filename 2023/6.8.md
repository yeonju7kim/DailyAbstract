ARTIC3D: Learning Robust Articulated 3D Shapes from Noisy Web Image Collections
- self-supervised framework to reconstruct per-instance 3D shapes from a sparse image collection in-the-wild
- ARTIC3D is built upon a skeleton-based surface representation and is further guided by 2D diffusion priors from Stable Diffusion
- First, we enhance the input images with occlusions/truncation via 2D diffusion to obtain cleaner mask estimates and semantic features
- Second, we perform diffusion-guided 3D optimization to estimate shape and texture that are of high-fidelity and faithful to input images. 
- We also propose a novel technique to calculate more stable image-level gradients via diffusion models compared to existing alternatives. 
- Finally, we produce realistic animations by fine-tuning the rendered shape and texture under rigid part transformations. 
> Noisy web image collections로 3D shape 만들기<br>
> 2D image cleaning, 3D optimization<br>
> 다시읽기
 
Designing a Better Asymmetric VQGAN for StableDiffusion
- StableDiffusion learns a diffusion model in the latent space via a VQGAN, ensuring both efficiency and quality.
- Motivation : vanilla VQGAN used in StableDiffusion leads to significant information loss, causing distortion artifacts even in non-edited image regions.
- asymmetric VQGAN with two simple designs
- 1. in addition to the input from the encoder, the decoder contains a conditional branch that incorporates information from task-specific priors, such as the unmasked image region in inpainting
- 2. the decoder is much heavier than the encoder, allowing for more detailed recovery while only slightly increasing the total inference cost.
