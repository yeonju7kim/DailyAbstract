## Testing Causal Models of Word Meaning in GPT-3 and -4
https://arxiv.org/pdf/2305.14630.pdf
- 어떻게 그 모델이 lexical concepts을 표현하는지는 unclear하다
- 이 논문은 lexical representations of GPT-3, GPT-4를 HIPE 이론의 관점으로 평가하는 논문이다.
  - concept representations 에 대한 이론
> 너무 관련 없어서 안읽음

##  Is ChatGPT a Good Causal Reasoner? A Comprehensive Evaluation.
https://arxiv.org/pdf/2305.07375.pdf
- ChatGPT의 causal reasoning capabilities에 대한 평가
  - 실험으로 good causal reasoner는 아니지만, causal interpreter라는 것을 밝혔다.
- serious hallucination on causal reasoning
  - causal과 non-causal relationships으로 인한 reporting biases 때문
- In-Context Learning(ICL), Chain-Of-Thought(COT)가 causal hallucinaton 더 악화했다.
- 실험 결과 prompt에 있는 causal concept의 경우 더 sensitive했고, closed-ended prompts가 더 좋았다.
- ChatGPT는 explicit causality를 더 잘 capture함
- lower event density와 smaller lexical distance between events에서 더 잘 기능했다.
> 신기하네 nlp에서 causal 을 어떻게 밝히지?
- Benchmark로 사용한 task
  - Event Causality Identification(ECI)
    - 한 문장안의 두 이벤트가 relationship이 있는지
    - commonsence도 필요하고, complex context를 이해해야함
  - Causal Discovery(CD)
    - broader, specialized knowledge를 가지고 있어야함
    - multiple choice, binary classification
  - Causal Explanation Generation(CEG)
    - causal relations between event를 text로 설명   
> 신기하네 caption들 간에도 causal relationship을 분석하는 연구가 있을까?

## Causality-aware Concept Extraction based on Knowledge-guided Prompting
https://arxiv.org/pdf/2305.01876.pdf
- concepts는 existing knowledge graph와 거리가 멀다
- PLMs은 text-based concept extraction(CE)로 많이 사용된다
- PLMs는 real causal effect가 아니라 coccurrence를 사용
- 이 페이퍼에서 Structural causal model (SCM)을 이용하여 PLM-based extractor를 제안
  - knowledge guided prompt로 intervention을 이용해서 concept bias를 alleviate
  - prompt가 topic을 adopts해서 entities와 biased concepts간의 spurious co-occurrence를 줄인다.
> 신기하네. 해당 주제에 맞게 prompt로 adapt하는데, 어떻게 하는거지.. 더 읽어볼까

## Supporting Vision-Language Model Inference with Causality-pruning Knowledge Prompt
https://arxiv.org/pdf/2205.11100.pdf
- 어떤 prompt를 써야하는지 잘 모름
- 이 논문에서는 prompt에 semantic information을 포함하는 것의 중요성을 탐구하고 설명함
  - 기존엔 그런 탐구없이 prompt를 generate함
- 기존에 prompt를 만드려면 domain 지식이 필요했고, time-consuming하다
- Causality pruning Knowledge prompt(CapKP)를 제안
  -  textual label을 query로 사용해서 ontological knowledge graph를 얻고, task-relevant semantic information을 탐고하는데 사용한다
  -  granger causality의 첫번째 principle을 이용하여 causality-pruning을 제안했다.
> knowledge graph로 causal pruning 이용해서 prompt 만든다.

## Fine-Grained Regional Prompt Tuning for Visual Abductive Reasoning
https://arxiv.org/pdf/2303.10428.pdf

https://arxiv.org/pdf/2207.11100.pdf


https://arxiv.org/pdf/2110.05208.pdf
---

https://arxiv.org/pdf/2305.11560.pdf


https://huggingface.co/blog/vision_language_pretraining
